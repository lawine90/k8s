boto3
pytrie
fastapi
uvicorn[standard]
transformers
sentencepiece
accelerate
protobuf
llama-cpp-python

# 10GB짜리 CUDA 버전 대신 2GB짜리 CPU 전용 버전을 명시
torch --index-url https://download.pytorch.org/whl/cpu