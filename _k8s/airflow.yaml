# ================================================
# 1. Airflow Namespace
# ================================================
apiVersion: v1
kind: Namespace
metadata:
  name: airflow
---


# ================================================
# 2. Airflow RBAC (KubernetesExecutor 필수)
# ================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: airflow-scheduler
  namespace: airflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: airflow-scheduler-role
  namespace: airflow
rules:
  - apiGroups: [""]
    resources: ["pods", "pods/log"]
    verbs: ["get", "list", "watch", "create", "update", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: airflow-scheduler-rolebinding
  namespace: airflow
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: airflow-scheduler-role
subjects:
  - kind: ServiceAccount
    name: airflow-scheduler
    namespace: airflow
---


# ================================================
# 3. Airflow Base (Namespace, Config, Secret, DBs)
# ================================================
# 에어플로우 config map 및 secret
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  namespace: airflow
data:
  #AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__EXECUTOR: KubernetesExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgresql:5432/airflow
  #AIRFLOW__CELERY__BROKER_URL: redis://airflow-redis:6379/0
  #AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-postgresql:5432/airflow
  AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
  AIRFLOW__WEBSERVER__WEB_SERVER_PORT: "8080"

  # airflow 내부 암호화 키
  AIRFLOW__CORE__FERNET_KEY: qz3pRw__AFapmX1aL4Bj34g3-MjyebVxvQCdxAyRiqM=

  # dag sync schedule
  AIRFLOW__CORE__DAG_DISCOVERY_SAFE_MODE: "False"
  AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: "120"

  # mysql access config
  MYSQL_HOST: mysql.mysql.svc.cluster.local
  MYSQL_PORT: "3306"
  MYSQL_USER: admin1
  MYSQL_PASSWORD: admin1
  MYSQL_DATABASE: airflow_db

  # worker의 task remote 로깅
  AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
  AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "s3://airflow-logs/"
  AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "minio_default"

  # [KubernetesExecutor 추가 설정]
  AIRFLOW__KUBERNETES__NAMESPACE: airflow

  # 워커 파드가 떴을 때 DAG PVC를 자동으로 마운트하도록 설정
  AIRFLOW__KUBERNETES__DAGS_VOLUME_CLAIM: airflow-dags-pvc
  AIRFLOW__KUBERNETES__DAGS_VOLUME_MOUNT_POINT: /opt/airflow/dags
  AIRFLOW__KUBERNETES__DAGS_VOLUME_SUBPATH: repo/dags

  # 워커 파드가 Git-Sync와 동일한 그룹 권한을 갖도록 설정
  AIRFLOW__KUBERNETES__WORKER_POD_FS_GROUP: "65533"
---

apiVersion: v1
kind: Secret
metadata:
  name: airflow-postgres-secret
  namespace: airflow
type: Opaque
stringData:
  postgres-user: airflow
  postgres-password: airflow
  postgres-db: airflow
---

apiVersion: v1
kind: Service
metadata:
  name: airflow-postgresql
  namespace: airflow
spec:
  ports: [{port: 5432, targetPort: 5432}]
  selector: {app: airflow-postgresql}
---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-postgresql
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-postgresql
  template:
    metadata:
      labels:
        app: airflow-postgresql
    spec:
      containers:
        - name: postgres
          image: postgres:15
          env:
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-db
          ports:
            - containerPort: 5432
          volumeMounts:
            - name: postgres-data
              mountPath: /var/lib/postgresql/data
      volumes:
        - name: postgres-data
          emptyDir: {}
---

## 셀러리 브로커용 레디스
#apiVersion: v1
#kind: Service
#metadata:
#  name: airflow-redis
#  namespace: airflow
#spec:
#  ports:
#    - port: 6379
#      targetPort: 6379
#  selector:
#    app: airflow-redis
#---
#apiVersion: apps/v1
#kind: Deployment
#metadata:
#  name: airflow-redis
#  namespace: airflow
#spec:
#  replicas: 1
#  selector:
#    matchLabels:
#      app: airflow-redis
#  template:
#    metadata:
#      labels:
#        app: airflow-redis
#    spec:
#      containers:
#        - name: redis
#          image: redis:7
#          ports:
#            - containerPort: 6379
#---

# minio dag task logging용 저장소
apiVersion: v1
kind: Secret
metadata:
  name: minio-secret
  namespace: airflow
type: Opaque
stringData:
  accesskey: minioadmin
  secretkey: minioadmin
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: airflow
spec:
  ports:
    - name: api
      port: 9000
      targetPort: 9000
    - name: console
      port: 9001
      targetPort: 9001
  selector:
    app: minio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
        - name: minio
          image: minio/minio:latest
          args: ["server", "/data", "--console-address", ":9001"]
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: accesskey
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: secretkey
          ports:
            - containerPort: 9000
            - containerPort: 9001
          volumeMounts:
            - name: minio-data
              mountPath: /data
      volumes:
        - name: minio-data
          emptyDir: {}
---

# ================================================
# 3. Airflow DAGs Storage (RWX PVC via NFS)
# ================================================
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: airflow-dags-pvc
  namespace: airflow
spec:
  accessModes:
    - ReadWriteMany  # NFS 덕분에 여러 파드에서 동시 읽기/쓰기 가능
  resources:
    requests:
      storage: 1Gi
  storageClassName: nfs-client # 위에서 만든 StorageClass 사용
---


# ================================================
# 4. Standalone Git-Sync Deployment
# ================================================
apiVersion: v1
kind: Secret
metadata:
  name: git-credentials
  namespace: airflow
data:
  # 기존 값 유지
  GITSYNC_USERNAME: biBsYXdpbmU5MAo=
  GITSYNC_PASSWORD: biBnaXRodWJfcGF0XzExQUxaWFk3UTBhREpiOFVMaFJJaXdfNlF2Q1FWN0dJWW5FcEc1RzJRZXBERFVUSzFWTTA3TENTRElQalVSbXhSTEczQ09XM0JRbTFhM240TEEK
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: git-sparse-config
  namespace: airflow
data:
  sparse-checkout-paths: |
    dags/
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-git-sync
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-git-sync
  template:
    metadata:
      labels:
        app: airflow-git-sync
    spec:
      securityContext:
        fsGroup: 65533 # Airflow 그룹 권한으로 파일 생성
      containers:
        - name: git-sync
          image: registry.k8s.io/git-sync/git-sync:v4.3.0
          env:
            - name: GITSYNC_REPO
              value: "https://github.com/lawine90/k8s.git"
            - name: GITSYNC_REF
              value: "main"
            - name: GITSYNC_ROOT
              value: "/git"
            - name: GITSYNC_DEST
              value: "repo"
            - name: GITSYNC_DEPTH
              value: "1"
            - name: GITSYNC_PERIOD
              value: "60s" # 단독 실행이므로 갱신 주기를 조금 더 짧게 설정해도 부담이 적음
            #- name: GITSYNC_SPARSE_CHECKOUT_FILE
            #  value: "/etc/git-sparse/sparse-checkout-paths"
            - name: GITSYNC_USERNAME
              valueFrom: {secretKeyRef: {name: git-credentials, key: GITSYNC_USERNAME}}
            - name: GITSYNC_PASSWORD
              valueFrom: {secretKeyRef: {name: git-credentials, key: GITSYNC_PASSWORD}}
          volumeMounts:
            - name: dags
              mountPath: /git       # 여기에 repo 디렉토리가 생성됨 (/git/repo/dags/...)
            #- name: git-sparse
            #  mountPath: /etc/git-sparse
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
        #- name: git-sparse
        #  configMap:
        #    name: git-sparse-config
---


# ================================================
# 5. Airflow Init
# ================================================
# 초기 job 생성:
# 1. DB 초기화: airflow는 초기 실행 시 airflow db init 또는 airflow db upgrade를 실행해서 메타데이터 DB에 스키마를 생성해야함
#   초기화를 해줘야 webserver, scheduler, worker에서 DB에 접속이 가능함
# 2. worker pod의 task logging 저장을 위한 minio_default 생성
# 3. airflow 계정 생성
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-init
  namespace: airflow
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: airflow-init
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          envFrom:
            - configMapRef:
                name: airflow-config
          command: [ "/bin/bash", "-c" ]
          args:
            - |
              echo "Waiting for PostgreSQL to be ready..."
              until nc -z airflow-postgresql 5432; do
              sleep 3
              echo "Waiting..."
              done
              
              echo "Initializing Airflow DB..."
              airflow db init
              
              echo "Creating MinIO connection..."
              airflow connections add 'minio_default' \
                --conn-type 's3' \
                --conn-login 'minioadmin' \
                --conn-password 'minioadmin' \
                --conn-extra '{"host": "http://minio.airflow.svc.cluster.local:9000"}'
              
              echo "Creating Airflow admin..."
              airflow users create \
                --username admin1 \
                --firstname Admin \
                --lastname User \
                --role Admin \
                --email admin1@example.com \
                --password admin1
              
              echo "Airflow initialization completed."
---

# ================================================
# 5. Airflow Core Components
# ================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-webserver
  template:
    metadata:
      labels:
        app: airflow-webserver
    spec:
      securityContext:
        fsGroup: 65533
      containers:
        - name: webserver
          image: labineseo90/airflow:2.10.5-custom
          args: ["webserver"]
          envFrom:
            - configMapRef:
                name: airflow-config
          ports:
            - containerPort: 8080
          # dag 저장용 pvc mount
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
              subPath: repo/dags
              readOnly: true
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  template:
    metadata:
      labels:
        app: airflow-scheduler
    spec:
      serviceAccountName: airflow-scheduler
      securityContext:
        fsGroup: 65533
      containers:
        - name: scheduler
          image: labineseo90/airflow:2.10.5-custom
          args: ["scheduler"]
          envFrom:
            - configMapRef:
                name: airflow-config
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
              subPath: repo/dags
              readOnly: true
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
---
#apiVersion: apps/v1
#kind: Deployment
#metadata:
#  name: airflow-worker
#  namespace: airflow
#spec:
#  replicas: 1
#  selector:
#    matchLabels:
#      app: airflow-worker
#  template:
#    metadata:
#      labels:
#        app: airflow-worker
#    spec:
#      securityContext:
#        fsGroup: 65533
#      containers:
#        - name: worker
#          #image: apache/airflow:2.10.2
#          image: labineseo90/airflow:2.10.5-custom
#          args: ["celery", "worker"]
#          envFrom:
#            - configMapRef:
#                name: airflow-config
#          # dag 저장용 pvc mount
#          volumeMounts:
#            - name: dags
#              mountPath: /opt/airflow/dags
#              subPath: repo/dags
#              readOnly: true
#      volumes:
#        - name: dags
#          persistentVolumeClaim:
#            claimName: airflow-dags-pvc
#---
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  namespace: airflow
spec:
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    app: airflow-webserver
---

# 인그레스 설정
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: airflow
  namespace: airflow
  annotations:
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
spec:
  ingressClassName: nginx
  rules:
    - host: local-airflow.duckdns.org
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: airflow-webserver
                port:
                  number: 8080
---
