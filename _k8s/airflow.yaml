# 클러스터에 에어플로우용 네임스페이스 생성
apiVersion: v1
kind: Namespace
metadata:
  name: airflow
---

# 에어플로우 config map 및 secret
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  namespace: airflow
data:
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgresql:5432/airflow
  AIRFLOW__CELERY__BROKER_URL: redis://airflow-redis:6379/0
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-postgresql:5432/airflow
  AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
  AIRFLOW__WEBSERVER__WEB_SERVER_PORT: "8080"

  # airflow 내부 암호화 키
  AIRFLOW__CORE__FERNET_KEY: qz3pRw__AFapmX1aL4Bj34g3-MjyebVxvQCdxAyRiqM=

  # dag sync schedule
  AIRFLOW__CORE__DAG_DISCOVERY_SAFE_MODE: "False"
  AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: "120"

  # mysql access config
  MYSQL_HOST: airflow-mysql.mysql.svc.cluster.local
  MYSQL_PORT: "3306"
  MYSQL_USER: admin1
  MYSQL_PASSWORD: admin1
  MYSQL_DATABASE: airflow_db
  #MYSQL_CONN_URL: "mysql+pymysql://admin1:admin1@airflow-mysql.mysql.svc.cluster.local:3306/airflow_db"

  # worker의 task remote 로깅
  AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
  AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "s3://airflow-logs/"
  AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "minio_default"
---

apiVersion: v1
kind: Secret
metadata:
  name: airflow-fernet-key
  namespace: airflow
type: Opaque
stringData:
  fernet-key: qz3pRw__AFapmX1aL4Bj34g3-MjyebVxvQCdxAyRiqM=
---

# 메타데이터용 postgre sql 생성
apiVersion: v1
kind: Secret
metadata:
  name: airflow-postgres-secret
  namespace: airflow
type: Opaque
stringData:
  postgres-user: airflow
  postgres-password: airflow
  postgres-db: airflow
---
apiVersion: v1
kind: Service
metadata:
  name: airflow-postgresql
  namespace: airflow
spec:
  ports:
    - port: 5432
      targetPort: 5432
  selector:
    app: airflow-postgresql
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-postgresql
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-postgresql
  template:
    metadata:
      labels:
        app: airflow-postgresql
    spec:
      containers:
        - name: postgres
          image: postgres:15
          env:
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-db
          ports:
            - containerPort: 5432
          volumeMounts:
            - name: postgres-data
              mountPath: /var/lib/postgresql/data
      volumes:
        - name: postgres-data
          emptyDir: {}
---

# 셀러리 브로커용 레디스
apiVersion: v1
kind: Service
metadata:
  name: airflow-redis
  namespace: airflow
spec:
  ports:
    - port: 6379
      targetPort: 6379
  selector:
    app: airflow-redis
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-redis
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-redis
  template:
    metadata:
      labels:
        app: airflow-redis
    spec:
      containers:
        - name: redis
          image: redis:7
          ports:
            - containerPort: 6379
---

# minio dag task logging용 저장소
apiVersion: v1
kind: Secret
metadata:
  name: minio-secret
  namespace: airflow
type: Opaque
stringData:
  accesskey: minioadmin
  secretkey: minioadmin
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: airflow
spec:
  ports:
    - name: api
      port: 9000
      targetPort: 9000
    - name: console
      port: 9001
      targetPort: 9001
  selector:
    app: minio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
        - name: minio
          image: minio/minio:latest
          args: ["server", "/data", "--console-address", ":9001"]
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: accesskey
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: secretkey
          ports:
            - containerPort: 9000
            - containerPort: 9001
          volumeMounts:
            - name: minio-data
              mountPath: /data
      volumes:
        - name: minio-data
          emptyDir: {}
---

# 초기 job 생성:
# 1. DB 초기화: airflow는 초기 실행 시 airflow db init 또는 airflow db upgrade를 실행해서 메타데이터 DB에 스키마를 생성해야함
#   초기화를 해줘야 webserver, scheduler, worker에서 DB에 접속이 가능함
# 2. worker pod의 task logging 저장을 위한 minio_default 생성
# 3. airflow 계정 생성
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-init
  namespace: airflow
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: airflow-init
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          envFrom:
            - configMapRef:
                name: airflow-config
          command: [ "/bin/bash", "-c" ]
          args:
            - |
              echo "Waiting for PostgreSQL to be ready..."
              until nc -z airflow-postgresql 5432; do
              sleep 3
              echo "Waiting..."
              done
              
              echo "Initializing Airflow DB..."
              airflow db init
              
              echo "Creating MinIO connection..."
              airflow connections add 'minio_default' \
                --conn-type 's3' \
                --conn-login 'minioadmin' \
                --conn-password 'minioadmin' \
                --conn-extra '{"host": "http://minio.airflow.svc.cluster.local:9000"}'
              
              echo "Creating Airflow admin..."
              airflow users create \
                --username admin1 \
                --firstname Admin \
                --lastname User \
                --role Admin \
                --email admin1@example.com \
                --password admin1
              
              echo "Airflow initialization completed."
---

# git-sync용 credential
apiVersion: v1
kind: Secret
metadata:
  name: git-credentials
  namespace: airflow
data:
  GITSYNC_USERNAME: biBsYXdpbmU5MAo=
  GITSYNC_PASSWORD: biBnaXRodWJfcGF0XzExQUxaWFk3UTBhREpiOFVMaFJJaXdfNlF2Q1FWN0dJWW5FcEc1RzJRZXBERFVUSzFWTTA3TENTRElQalVSbXhSTEczQ09XM0JRbTFhM240TEEK
---

# 레포의 특정 path만 클론하기 위한 config
# 레포를 모두 클론할 필요는 없으므로 특정 path만 클론
apiVersion: v1
kind: ConfigMap
metadata:
  name: git-sparse-config
  namespace: airflow
data:
  sparse-checkout-paths: |
    dags/
---

### airflow component: webserver, scheduler, worker
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-webserver
  template:
    metadata:
      labels:
        app: airflow-webserver
    spec:
      # Git-sync가 접근하는 볼륨의 권한을 65533:65533으로 강제 설정
      initContainers:
        - name: fix-permissions
          image: busybox:1.36
          command: [ "sh", "-c", "chown -R 65533:65533 /git" ]
          securityContext:
            # Init 컨테이너가 chown을 실행하기 위해 root 권한이 필요
            runAsUser: 0
          volumeMounts:
            - name: dags
              mountPath: /git
      # Airflow 프로세스가 생성하는 파일의 그룹을 65533으로 설정하여 Git-sync가 삭제할 수 있도록 함
      securityContext:
        fsGroup: 65533
      containers:
        - name: webserver
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          args: ["webserver"]
          envFrom:
            - configMapRef:
                name: airflow-config
          ports:
            - containerPort: 8080
          # dag 저장용 pvc mount
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
              subPath: k8s.git/dags
              readOnly: true
        - name: git-sync
          image: registry.k8s.io/git-sync/git-sync:v4.3.0
          args:
            - --sparse-checkout-file=/etc/git-sparse/sparse-checkout-paths
          env:
            - name: GITSYNC_REPO
              value: "https://github.com/lawine90/k8s.git"
            - name: GITSYNC_REF
              value: "main"
            - name: GITSYNC_ROOT
              value: "/git"
            - name: GITSYNC_DEST
              value: ""
            - name: GITSYNC_DEPTH
              value: "1"
            - name: GITSYNC_PERIOD
              value: "300s"
            - name: GITSYNC_USERNAME
              valueFrom:
                secretKeyRef:
                  name: git-credentials
                  key: GITSYNC_USERNAME
            - name: GITSYNC_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: git-credentials
                  key: GITSYNC_PASSWORD
          volumeMounts:
            - name: dags
              mountPath: /git
            - name: git-sparse
              mountPath: /etc/git-sparse
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
        - name: git-sparse
          configMap:
            name: git-sparse-config
            items:
              - key: sparse-checkout-paths
                path: sparse-checkout-paths
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  template:
    metadata:
      labels:
        app: airflow-scheduler
    spec:
      # Git-sync가 접근하는 볼륨의 권한을 65533:65533으로 강제 설정
      initContainers:
        - name: fix-permissions
          image: busybox:1.36
          command: [ "sh", "-c", "chown -R 65533:65533 /git" ]
          securityContext:
            # Init 컨테이너가 chown을 실행하기 위해 root 권한이 필요
            runAsUser: 0
          volumeMounts:
            - name: dags
              mountPath: /git
      # Airflow 프로세스가 생성하는 파일의 그룹을 65533으로 설정하여 Git-sync가 삭제할 수 있도록 함
      securityContext:
        fsGroup: 65533
      containers:
        - name: scheduler
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          args: ["scheduler"]
          envFrom:
            - configMapRef:
                name: airflow-config
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
              subPath: k8s.git/dags
              readOnly: true
        - name: git-sync
          image: registry.k8s.io/git-sync/git-sync:v4.3.0
          args:
            - --sparse-checkout-file=/etc/git-sparse/sparse-checkout-paths
          env:
            - name: GITSYNC_REPO
              value: "https://github.com/lawine90/k8s.git"
            - name: GITSYNC_REF
              value: "main"
            - name: GITSYNC_ROOT
              value: "/git"
            - name: GITSYNC_DEST
              value: ""
            - name: GITSYNC_DEPTH
              value: "1"
            - name: GITSYNC_PERIOD
              value: "300s"
            - name: GITSYNC_USERNAME
              valueFrom:
                secretKeyRef:
                  name: git-credentials
                  key: GITSYNC_USERNAME
            - name: GITSYNC_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: git-credentials
                  key: GITSYNC_PASSWORD
          volumeMounts:
            - name: dags
              mountPath: /git
            - name: git-sparse
              mountPath: /etc/git-sparse
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
        - name: git-sparse
          configMap:
            name: git-sparse-config
            items:
              - key: sparse-checkout-paths
                path: sparse-checkout-paths
#      # pvc mount
#      volumes:
#        - name: dags
#          persistentVolumeClaim:
#            claimName: airflow-dags-pvc
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-worker
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-worker
  template:
    metadata:
      labels:
        app: airflow-worker
    spec:
      securityContext:
        fsGroup: 65533
      containers:
        - name: worker
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          args: ["celery", "worker"]
          envFrom:
            - configMapRef:
                name: airflow-config
          # dag 저장용 pvc mount
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
              subPath: k8s.git/dags
              readOnly: true
#        - name: git-sync
#          image: registry.k8s.io/git-sync/git-sync:v4.3.0
#          env:
#            - name: GITSYNC_REPO
#              value: "https://github.com/lawine90/k8s.git"
#            - name: GITSYNC_REF
#              value: "main"
#            - name: GITSYNC_ROOT
#              value: "/git"
#            - name: GITSYNC_DEST
#              value: ""
#            - name: GITSYNC_DEPTH
#              value: "1"
#            - name: GITSYNC_PERIOD
#              value: "300s"
#            - name: GITSYNC_USERNAME
#              valueFrom:
#                secretKeyRef:
#                  name: git-credentials
#                  key: GITSYNC_USERNAME
#            - name: GITSYNC_PASSWORD
#              valueFrom:
#                secretKeyRef:
#                  name: git-credentials
#                  key: GITSYNC_PASSWORD
#          volumeMounts:
#            - name: dags
#              mountPath: /git
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  namespace: airflow
spec:
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    app: airflow-webserver
---

# 인그레스 설정
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: airflow
  namespace: airflow
  annotations:
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
spec:
  ingressClassName: nginx
  rules:
    - host: local-airflow.duckdns.org
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: airflow-webserver
                port:
                  number: 8080
---

# dag 생성용 pvc
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: airflow-dags-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: standard
  hostPath:
    path: /mnt/data/airflow/dags
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: airflow-dags-pvc
  namespace: airflow
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: standard
---
