# 클러스터에 에어플로우용 네임스페이스 생성
apiVersion: v1
kind: Namespace
metadata:
  name: airflow
---

# 에어플로우 config map 및 secret
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  namespace: airflow
data:
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgresql:5432/airflow
  AIRFLOW__CELERY__BROKER_URL: redis://airflow-redis:6379/0
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://airflow:airflow@airflow-postgresql:5432/airflow
  AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
  AIRFLOW__WEBSERVER__WEB_SERVER_PORT: "8080"

  # airflow 내부 암호화 키
  AIRFLOW__CORE__FERNET_KEY: qz3pRw__AFapmX1aL4Bj34g3-MjyebVxvQCdxAyRiqM=

  # dag sync schedule
  AIRFLOW__CORE__DAG_DISCOVERY_SAFE_MODE: "False"
  AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: "120"

  # mysql access config
  MYSQL_HOST: airflow-mysql.mysql.svc.cluster.local
  MYSQL_PORT: "3306"
  MYSQL_USER: admin1
  MYSQL_PASSWORD: admin1
  MYSQL_DATABASE: airflow_db
  #MYSQL_CONN_URL: "mysql+pymysql://admin1:admin1@airflow-mysql.mysql.svc.cluster.local:3306/airflow_db"

  # worker의 task remote 로깅
  AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
  AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "s3://airflow-logs/"
  AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "minio_default"
---

apiVersion: v1
kind: Secret
metadata:
  name: airflow-fernet-key
  namespace: airflow
type: Opaque
stringData:
  fernet-key: qz3pRw__AFapmX1aL4Bj34g3-MjyebVxvQCdxAyRiqM=
---

# 메타데이터용 postgre sql 생성
apiVersion: v1
kind: Secret
metadata:
  name: airflow-postgres-secret
  namespace: airflow
type: Opaque
stringData:
  postgres-user: airflow
  postgres-password: airflow
  postgres-db: airflow
---
apiVersion: v1
kind: Service
metadata:
  name: airflow-postgresql
  namespace: airflow
spec:
  ports:
    - port: 5432
      targetPort: 5432
  selector:
    app: airflow-postgresql
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-postgresql
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-postgresql
  template:
    metadata:
      labels:
        app: airflow-postgresql
    spec:
      containers:
        - name: postgres
          image: postgres:15
          env:
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-user
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-password
            - name: POSTGRES_DB
              valueFrom:
                secretKeyRef:
                  name: airflow-postgres-secret
                  key: postgres-db
          ports:
            - containerPort: 5432
          volumeMounts:
            - name: postgres-data
              mountPath: /var/lib/postgresql/data
      volumes:
        - name: postgres-data
          emptyDir: {}
---

# 셀러리 브로커용 레디스
apiVersion: v1
kind: Service
metadata:
  name: airflow-redis
  namespace: airflow
spec:
  ports:
    - port: 6379
      targetPort: 6379
  selector:
    app: airflow-redis
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-redis
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-redis
  template:
    metadata:
      labels:
        app: airflow-redis
    spec:
      containers:
        - name: redis
          image: redis:7
          ports:
            - containerPort: 6379
---

# minio dag task logging용 저장소
apiVersion: v1
kind: Secret
metadata:
  name: minio-secret
  namespace: airflow
type: Opaque
stringData:
  accesskey: minioadmin
  secretkey: minioadmin
---
apiVersion: v1
kind: Service
metadata:
  name: minio
  namespace: airflow
spec:
  ports:
    - name: api
      port: 9000
      targetPort: 9000
    - name: console
      port: 9001
      targetPort: 9001
  selector:
    app: minio
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: minio
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: minio
  template:
    metadata:
      labels:
        app: minio
    spec:
      containers:
        - name: minio
          image: minio/minio:latest
          args: ["server", "/data", "--console-address", ":9001"]
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: accesskey
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: minio-secret
                  key: secretkey
          ports:
            - containerPort: 9000
            - containerPort: 9001
          volumeMounts:
            - name: minio-data
              mountPath: /data
      volumes:
        - name: minio-data
          emptyDir: {}
---

# 초기 job 생성:
# 1. DB 초기화: airflow는 초기 실행 시 airflow db init 또는 airflow db upgrade를 실행해서 메타데이터 DB에 스키마를 생성해야함
#   초기화를 해줘야 webserver, scheduler, worker에서 DB에 접속이 가능함
# 2. worker pod의 task logging 저장을 위한 minio_default 생성
# 3. airflow 계정 생성
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-init
  namespace: airflow
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: airflow-init
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          envFrom:
            - configMapRef:
                name: airflow-config
          command: [ "/bin/bash", "-c" ]
          args:
            - |
              echo "Waiting for PostgreSQL to be ready..."
              until nc -z airflow-postgresql 5432; do
              sleep 3
              echo "Waiting..."
              done
              
              echo "Initializing Airflow DB..."
              airflow db init
              
              echo "Creating MinIO connection..."
              airflow connections add 'minio_default' \
                --conn-type 's3' \
                --conn-login 'minioadmin' \
                --conn-password 'minioadmin' \
                --conn-extra '{"host": "http://minio.airflow.svc.cluster.local:9000"}'
              
              echo "Creating Airflow admin..."
              airflow users create \
                --username admin1 \
                --firstname Admin \
                --lastname User \
                --role Admin \
                --email admin1@example.com \
                --password admin1
              
              echo "Airflow initialization completed."
---
#
## webserver pod에 접속하여 계정 생성
#apiVersion: batch/v1
#kind: Job
#metadata:
#  name: airflow-create-admin
#  namespace: airflow
#spec:
#  template:
#    spec:
#      restartPolicy: OnFailure
#      containers:
#        - name: create-admin
#          #image: apache/airflow:2.10.2
#          image: labineseo90/airflow:2.10.5-custom
#          command: ["bash", "-c"]
#          args:
#            - |
#              airflow users create \
#                --username admin1 \
#                --firstname Admin \
#                --lastname User \
#                --role Admin \
#                --email admin1@example.com \
#                --password admin1
#          env:
#            - name: AIRFLOW__CORE__EXECUTOR
#              value: LocalExecutor
#            - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
#              value: postgresql+psycopg2://airflow:airflow@airflow-postgresql:5432/airflow
#---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-webserver
  template:
    metadata:
      labels:
        app: airflow-webserver
    spec:
      containers:
        - name: webserver
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          args: ["webserver"]
          envFrom:
            - configMapRef:
                name: airflow-config
          ports:
            - containerPort: 8080
          # dag 저장용 pvc mount
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
      # pvc mount
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
#        - name: git-sync
#          image: k8s.gcr.io/git-sync/git-sync:v4.0.0
#          env:
#            - name: GIT_SYNC_REPO
#              value: "https://github.com/my-org/airflow-dags.git"
#            - name: GIT_SYNC_BRANCH
#              value: "main"
#            - name: GIT_SYNC_ROOT
#              value: "/git"
#            - name: GIT_SYNC_DEST
#              value: "dags"
#          volumeMounts:
#            - name: dags
#              mountPath: /git
#      volumes:
#        - name: dags
#          emptyDir: { }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  template:
    metadata:
      labels:
        app: airflow-scheduler
    spec:
      containers:
        - name: scheduler
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          args: ["scheduler"]
          envFrom:
            - configMapRef:
                name: airflow-config
          # pvc mount
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
      # pvc mount
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-worker
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-worker
  template:
    metadata:
      labels:
        app: airflow-worker
    spec:
      containers:
        - name: worker
          #image: apache/airflow:2.10.2
          image: labineseo90/airflow:2.10.5-custom
          args: ["celery", "worker"]
          envFrom:
            - configMapRef:
                name: airflow-config
          volumeMounts:
            - name: dags
              mountPath: /opt/airflow/dags
      volumes:
        - name: dags
          persistentVolumeClaim:
            claimName: airflow-dags-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  namespace: airflow
spec:
  ports:
    - port: 8080
      targetPort: 8080
  selector:
    app: airflow-webserver
---

# 인그레스 설정
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: airflow
  namespace: airflow
  annotations:
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
spec:
  ingressClassName: nginx
  rules:
    - host: local-airflow.duckdns.org
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: airflow-webserver
                port:
                  number: 8080
---

# dag 생성용 pvc
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: airflow-dags-pv
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: standard
  hostPath:
    path: /mnt/data/airflow/dags
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: airflow-dags-pvc
  namespace: airflow
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: standard
---
